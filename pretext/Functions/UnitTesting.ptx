<?xml version="1.0"?>
<section xml:id="functions_unit-testing">
  <title>Unit Testing</title>
  <introduction xml:id="functions_unit-testing-introduction">
	  <p>A <term>test case</term> expresses requirements for a program, in a way that can be checked automatically. Specifically, a test
				asserts something about the state of the program at a particular point in its execution. A <term>unit test</term> is an automatic
				procedure used to validate that individual units of code are working properly. A function is one form of a unit.
				A collection of these unit tests is called a <term>test suite</term>.</p>
	  <p>We have previously suggested that it's a good idea to first write down comments about what your code is supposed to do,
				before actually writing the code. It is an even better idea to write down some test cases before writing a program.</p>
	  <p>There are several reasons why it's a good habit to write test cases.</p>
	  <p>
		<ul>
		  <li>
			<p>Before we write code, we have in mind what it <em>should</em> do, but those thoughts may be a little vague. Writing down test cases forces us to be more concrete about what should happen.</p>
		  </li>
		  <li>
			<p>As we write the code, the test cases can provide automated feedback. You've actually been the beneficiary of such automated feedback via test cases throughout this book in some of the activecode windows and almost all of the exercises. We wrote the code for those test cases but kept it hidden, so as not to confuse you and also to avoid giving away the answers. You can get some of the same benefit from writing your own test cases.</p>
		  </li>
		  <li>
			<p>In larger software projects, the set of test cases can be run every time a change is made to the code base. <term>Unit tests</term> check that small bits of code are correctly implemented.</p>
		  </li>
		</ul>
	  </p>
	  <p>You have been following this pattern in the class so far, even if it is unconsciously. The test cases we give for each assessment can be thought of as unit tests. 
	  We give these to you when the assessment is assigned because it is so helpful to have while you are writing code.</p>
	  <p>One way to implement unit tests in Python, the same way our test cases do it, is with <c>assert</c>.</p>
	  <p>
		<ul>
		  <li>
			<p>Following the word assert there will be a python expression.</p>
		  </li>
		  <li>
			<p>If that expression evaluates to the Boolean <c>False</c>, then the interpreter will raise a runtime error.</p>
		  </li>
		  <li>
			<p>If the expression evaluates to <c>True</c>, then nothing happens and the execution goes on to the next line of code.</p>
		  </li>
		</ul>
	  </p>
	  <p>Take a look at the way assert is used in the following code.</p>
	  <program xml:id="ch8_sec9_p1" interactive="activecode" language="python">
		<input>
	assert type(9//5) == int
	assert type(9.0//5) == int
			</input>
	  </program>
	  <p>In the code above, we explicitly state some natural assumptions about how truncated division might work in python.
				It turns out that the second asumption is wrong: <c>9.0//5</c> produces <c>2.0</c>, a floating point value!</p>
	  <p>The python interpreter does not enforce restrictions about the data types of objects that can be bound to particular
				variables; however, type checking could alert us that something has gone wrong in our program execution. If we are
				assuming at that <c>x</c> is a list, but it's actually an integer, then at some point later in the program execution,
				there will probably be an error. We can add <c>assert</c> statements that will cause an error to be flagged sooner rather
				than later, which might make it a lot easier to debug.</p>
	  <p>
		<term>Check your understanding</term>
	  </p>
	  <exercise label="ch8_sec9_q1">
		<statement>
		  <p>When <c>assert x==y</c> is executed and x and y have the same values, what will happen?</p>
		</statement>
		<choices>
		  <choice>
			<statement>
			  <p>A runtime error will occur</p>
			</statement>
			<feedback>
						The expression ``x==y`` evaluates to ``True``
					</feedback>
		  </choice>
		  <choice>
			<statement>
			  <p>A message is printed out saying that the test failed.</p>
			</statement>
			<feedback>
						The expression ``x==y`` evaluates to ``True``
					</feedback>
		  </choice>
		  <choice>
			<statement>
			  <p>x will get the value that y currently has</p>
			</statement>
			<feedback>
						``x==y`` is a Boolean expression, not an assignment statement
					</feedback>
		  </choice>
		  <choice correct="yes">
			<statement>
			  <p>Nothing will happen</p>
			</statement>
			<feedback>
						The expression ``x==y`` evaluates to ``True``
					</feedback>
		  </choice>
		  <choice>
			<statement>
			  <p>A message is printed out saying that the test passed.</p>
			</statement>
			<feedback>
						When an assertion test passes, no message is printed.
					</feedback>
		  </choice>
		</choices>
	  </exercise>
  </introduction>
  <subsection xml:id="functions_assert-with-for-loops">
    <title><c>assert</c> with <c>for</c> loops</title>
    <p>Why would you ever want to write a line of code that can never compute anything useful for you, but sometimes causes
                a runtime error? For all the reasons we described above about the value of automated tests. You want a test that
                will alert that you that some condition you assumed was true is not in fact true. It's much better to be alerted to
                that fact right away than to have some unexpected result much later in your program execution, which you will have
                trouble tracing to the place where you had an error in your code.</p>
    <p>Why doesn't <c>assert</c> print out something saying that the test passed? The reason is that you don't want to clutter
                up your output window with the results of automated tests that pass. You just want to know when one of your tests
                fails. In larger projects, other testing harnesses are used instead of <c>assert</c>, such as the python <c>unittest</c>
                module. Those provide some output summarizing tests that have passed as well as those that failed. In this textbook,
                we will just use simple <c>assert</c> statements for automated tests.</p>
    <p>In the code below, <c>lst</c> is bound to a list object. In python, not all the elements of a list have to be of the
                same type. We can check that they all have the same type and get an error if they are not. Notice that with <c>lst2</c>,
                one of the assertions fails.</p>
    <program xml:id="ch8_sec9_p2" interactive="activecode" language="python">
      <input>
lst = ['a', 'b', 'c']
first_type = type(lst[0])
for item in lst:
    assert type(item) == first_type

lst2 = ['a', 'b', 'c', 17]
first_type = type(lst2[0])
for item in lst2:
    assert type(item) == first_type
        </input>
    </program>
  </subsection>
  <subsection xml:id="functions_return-value-tests">
    <title>Return Value Tests</title>
    <p>Testing whether a function returns the correct value is the easiest test case to define. You simply check whether the
                result of invoking the function on a particular input produces the particular output that you expect. Take a look at
                the following code.</p>
    <program xml:id="ch8_sec9_p3" interactive="activecode" language="python">
      <input>
def square(x):
#raise x to the second power
    return x*x
print('testing square function')
assert square(3) == 9
        </input>
    </program>
    <p>Because each test checks whether a function works properly on specific inputs, the test cases will never be complete: in
                principle, a function might work properly on all the inputs that are tested in the test cases, but still not work
                properly on some other inputs. That's where the art of defining test cases comes in: you try to find specific inputs that
                are representative of all the important kinds of inputs that might ever be passed to the function.</p>
    <exercise label="ch8_sec9_q2">
      <statement>
        <p>For the hangman game, this &#x2018;blanked' function takes a word and some letters that have been guessed, and returns a version
                of the word with _ for all the letters that haven't been guessed. Which of the following is the correct way to write
                a test to check that &#x2018;under' will be blanked as <c>'u_d__'</c> when the user has guessed letters d and u so far?</p>
      </statement>
      <choices>
        <choice>
          <statement>
            <p>assert blanked('under', 'du', 'u_d__') == True</p>
          </statement>
          <feedback>
                    blanked only takes two inputs; this provides three inputs to the blanked function
                </feedback>
        </choice>
        <choice>
          <statement>
            <p>assert blanked('under', 'u_d__') == 'du'</p>
          </statement>
          <feedback>
                    The second argument to the blanked function should be the letters that have been guessed, not the blanked version of the word
                </feedback>
        </choice>
        <choice correct="yes">
          <statement>
            <p>assert blanked('under', 'du') == 'u_d__'</p>
          </statement>
          <feedback>
                    This checks whether the value returned from the blanked function is 'u_d__'.
                </feedback>
        </choice>
      </choices>
    </exercise>
  </subsection>
</section>
